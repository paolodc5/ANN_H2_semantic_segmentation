{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world prova\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "RUNNING_IN_KAGGLE = 'KAGGLE_URL_BASE' in os.environ\n",
    "\n",
    "if RUNNING_IN_KAGGLE:\n",
    "    DATA_PATH = '/kaggle/input/mars-for-students-cleaned-fixed'\n",
    "else:\n",
    "    DATA_PATH = './data/'\n",
    "\n",
    "DATA_PATH\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {tfk.__version__}\")\n",
    "print(f\"GPU devices: {len(tf.config.list_physical_devices('GPU'))}\")\n",
    "# Set seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "\n",
    "# Set environment variables before importing modules\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# Import necessary modules\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set seeds for random number generators in NumPy and Python\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Import TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "\n",
    "# Set seed for TensorFlow\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "\n",
    "# Reduce TensorFlow verbosity\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# Print TensorFlow version\n",
    "print(tf.__version__)\n",
    "\n",
    "# Import other libraries\n",
    "import os\n",
    "import math\n",
    "from PIL import Image\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure plot display settings\n",
    "sns.set(font_scale=1.4)\n",
    "sns.set_style('white')\n",
    "plt.rc('font', size=14)\n",
    "%matplotlib inline\n",
    "data = os.path.join(DATA_PATH, \"mars_for_students_cleaned_fixed.npz\")\n",
    "data = np.load(data)\n",
    "\n",
    "X_train_val = data[\"training_img\"]\n",
    "y_train_val = data[\"training_masks\"]\n",
    "\n",
    "X_test = data[\"test_set\"]\n",
    "\n",
    "print(f\"Training X shape: {X_train_val.shape}\")\n",
    "print(f\"Training y shape: {y_train_val.shape}\")\n",
    "print(f\"Test X shape: {X_test.shape}\")\n",
    "# Set batch size for training\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Set learning rate for the optimiser\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# Set early stopping patience threshold\n",
    "PATIENCE = 30\n",
    "\n",
    "# Set maximum number of training epochs\n",
    "EPOCHS = 1000\n",
    "\n",
    "# Set data split size for training and validation\n",
    "SPLITS_SIZE = 300\n",
    "# Add color channel and rescale pixels between 0 and 1\n",
    "X_train_val = X_train_val[..., np.newaxis] / 255.0\n",
    "y_train_val = y_train_val[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis] / 255.0\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=SPLITS_SIZE, random_state=seed )\n",
    "\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "print(f\"Input shape: {input_shape}\")\n",
    "print(f\"mask shape: {y_train.shape[1:]}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "label_name = {0: \"Background\",\n",
    "    1: \"Soil\",\n",
    "    2: \"Bedrock\",\n",
    "    3: \"Sand\",\n",
    "    4: \"Big Rock\"\n",
    "    }\n",
    "'''geometrical transformations must be specified on both images and labels,\n",
    "thus it is much easier to apply them separately and them feed the already\n",
    "augmented versions.\n",
    "ALSO LABELS MUST BE AUGMENTED!'''\n",
    "\n",
    "@tf.function\n",
    "def random_flip(image, label, seed=None):\n",
    "    \"\"\"Consistent random horizontal flip.\"\"\"\n",
    "    if seed is None:\n",
    "        seed = np.random.randint(0, 1000000)\n",
    "    flip_prob = tf.random.uniform([], seed=seed)\n",
    "    image = tf.cond(\n",
    "        flip_prob > 0.5,\n",
    "        lambda: tf.image.flip_left_right(image),\n",
    "        lambda: image\n",
    "    )\n",
    "    label = tf.cond(\n",
    "        flip_prob > 0.5,\n",
    "        lambda: tf.image.flip_left_right(label),\n",
    "        lambda: label\n",
    "    )\n",
    "    return image, label\n",
    "def make_dataset(X, y, batch_size, shuffle=True, augment=False, seed=None):\n",
    "    \"\"\"\n",
    "    Create a memory-efficient TensorFlow dataset.\n",
    "    \"\"\"\n",
    "    # Create dataset from file paths\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=batch_size * 2, seed=seed)\n",
    "\n",
    "    if augment:\n",
    "        dataset = dataset.map(\n",
    "            lambda x, y: random_flip(x, y, seed=seed),\n",
    "            num_parallel_calls=tf.data.AUTOTUNE\n",
    "        )\n",
    "\n",
    "    # Batch the data\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=False)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE) #speedup, prec arica le immagine\n",
    "\n",
    "    return dataset\n",
    "# Create the datasets\n",
    "print(\"Creating datasets...\")\n",
    "train_dataset = make_dataset(\n",
    "    X_train, y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    augment=False,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "val_dataset = make_dataset(\n",
    "    X_val, y_val,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Datasets created!\")\n",
    "\n",
    "# Check the shape of the data\n",
    "for images, labels in train_dataset.take(1):\n",
    "    input_shape = images.shape[1:]\n",
    "    print(f\"\\nInput shape: {input_shape}\")\n",
    "    print(\"Images shape:\", images.shape)\n",
    "    print(\"Labels shape:\", labels.shape)\n",
    "    print(\"Labels dtype:\", labels.dtype)\n",
    "    break\n",
    "def create_segmentation_colormap(num_classes):\n",
    "    \"\"\"\n",
    "    Create a linear colormap using a predefined palette.\n",
    "    Uses 'viridis' as default because it is perceptually uniform\n",
    "    and works well for colorblindness.\n",
    "    \"\"\"\n",
    "    return plt.cm.viridis(np.linspace(0, 1, num_classes))\n",
    "\n",
    "def apply_colormap(label, colormap=None):\n",
    "    \"\"\"\n",
    "    Apply the colormap to a label.\n",
    "    \"\"\"\n",
    "    # Ensure label is 2D\n",
    "    label = np.squeeze(label)\n",
    "\n",
    "    if colormap is None:\n",
    "        num_classes = len(np.unique(label))\n",
    "        colormap = create_segmentation_colormap(num_classes)\n",
    "\n",
    "    # Apply the colormap\n",
    "    colored = colormap[label.astype(int)]\n",
    "\n",
    "    return colored\n",
    "\n",
    "def plot_sample_batch(dataset, num_samples=3):\n",
    "    \"\"\"\n",
    "    Display some image and label pairs from the dataset.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 4*num_samples))\n",
    "\n",
    "    for images, labels in dataset.take(1):\n",
    "        labels_np = labels.numpy()\n",
    "        num_classes = len(np.unique(labels_np))\n",
    "        colormap = create_segmentation_colormap(num_classes)\n",
    "\n",
    "        for j in range(min(num_samples, len(images))):\n",
    "            # Plot original image\n",
    "            plt.subplot(num_samples, 2, j*2 + 1)\n",
    "            plt.imshow(images[j], cmap='gray')\n",
    "            plt.title(f'Image {j+1}')\n",
    "            plt.axis('off')\n",
    "\n",
    "            # Plot colored label\n",
    "            plt.subplot(num_samples, 2, j*2 + 2)\n",
    "            colored_label = apply_colormap(labels_np[j], colormap)\n",
    "            plt.imshow(colored_label)\n",
    "            plt.title(f'Label {j+1}')\n",
    "            plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# Visualize examples from the training set\n",
    "print(\"Visualizing examples from the training set:\")\n",
    "plot_sample_batch(train_dataset, num_samples=3)\n",
    "def unet_block(input_tensor, filters, kernel_size=3, activation='relu', stack=2, name=''):\n",
    "    # Initialise the input tensor\n",
    "    x = input_tensor\n",
    "\n",
    "    # Apply a sequence of Conv2D, Batch Normalisation, and Activation layers for the specified number of stacks\n",
    "    for i in range(stack):\n",
    "        x = tfkl.Conv2D(filters, kernel_size=kernel_size, padding='same', name=name + 'conv' + str(i + 1))(x)\n",
    "        x = tfkl.BatchNormalization(name=name + 'bn' + str(i + 1))(x)\n",
    "        x = tfkl.Activation(activation, name=name + 'activation' + str(i + 1))(x)\n",
    "\n",
    "    # Return the transformed tensor\n",
    "    return x\n",
    "def get_unet_model(input_shape=(64, 128, 1), num_classes=num_classes, seed=seed):\n",
    "    tf.random.set_seed(seed)\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n",
    "\n",
    "    # Downsampling path\n",
    "    down_block_1 = unet_block(input_layer, 32, name='down_block1_')\n",
    "    d1 = tfkl.MaxPooling2D()(down_block_1)\n",
    "\n",
    "    down_block_2 = unet_block(d1, 64, name='down_block2_')\n",
    "    d2 = tfkl.MaxPooling2D()(down_block_2)\n",
    "\n",
    "    # Bottleneck\n",
    "    bottleneck = unet_block(d2, 128, name='bottleneck')\n",
    "\n",
    "    # Upsampling path\n",
    "    u1 = tfkl.UpSampling2D()(bottleneck)\n",
    "    u1 = tfkl.Concatenate()([u1, down_block_2])\n",
    "    u1 = unet_block(u1, 64, name='up_block1_')\n",
    "\n",
    "    u2 = tfkl.UpSampling2D()(u1)\n",
    "    u2 = tfkl.Concatenate()([u2, down_block_1])\n",
    "    u2 = unet_block(u2, 32, name='up_block2_')\n",
    "\n",
    "    # Output Layer\n",
    "    output_layer = tfkl.Conv2D(num_classes, kernel_size=1, padding='same', activation=\"softmax\", name='output_layer')(u2)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='UNet')\n",
    "    return model\n",
    "\n",
    "def get_deep_unet_model(input_shape=(64, 128, 1), num_classes=num_classes, seed=seed):\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    inputs = tfkl.Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    c1 = unet_block(inputs, 64, name='enc1_')\n",
    "    p1 = tfkl.MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = unet_block(p1, 128, name='enc2_')\n",
    "    p2 = tfkl.MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    c3 = unet_block(p2, 256, name='enc3_')\n",
    "    p3 = tfkl.MaxPooling2D((2, 2))(c3)\n",
    "    \n",
    "    c4 = unet_block(p3, 512, name='enc4_')\n",
    "    p4 = tfkl.MaxPooling2D((2, 2))(c4)\n",
    "    \n",
    "    # Bottleneck\n",
    "    bn = unet_block(p4, 1024, name='bn_')\n",
    "    \n",
    "    # Decoder\n",
    "    u4 = tfkl.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(bn)\n",
    "    u4 = tfkl.concatenate([u4, c4])\n",
    "    c5 = unet_block(u4, 512, name='dec4_')\n",
    "    \n",
    "    u3 = tfkl.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u3 = tfkl.concatenate([u3, c3])\n",
    "    c6 = unet_block(u3, 256, name='dec3_')\n",
    "    \n",
    "    u2 = tfkl.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u2 = tfkl.concatenate([u2, c2])\n",
    "    c7 = unet_block(u2, 128, name='dec2_')\n",
    "    \n",
    "    u1 = tfkl.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u1 = tfkl.concatenate([u1, c1])\n",
    "    c8 = unet_block(u1, 64, name='dec1_')\n",
    "    \n",
    "    outputs = tfkl.Conv2D(num_classes, (1, 1), activation='softmax')(c8)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "model = get_deep_unet_model()\n",
    "\n",
    "# Print a detailed summary of the model with expanded nested layers and trainable parameters.\n",
    "model.summary(expand_nested=True, show_trainable=True)\n",
    "\n",
    "# Generate and display a graphical representation of the model architecture.\n",
    "tf.keras.utils.plot_model(model, expand_nested=True, dpi=70)\n",
    "# Define custom Mean Intersection Over Union metric\n",
    "class MeanIntersectionOverUnion(tf.keras.metrics.MeanIoU):\n",
    "    def __init__(self, num_classes, labels_to_exclude=None, name=\"mean_iou\", dtype=None):\n",
    "        super(MeanIntersectionOverUnion, self).__init__(num_classes=num_classes, name=name, dtype=dtype)\n",
    "        if labels_to_exclude is None:\n",
    "            labels_to_exclude = [0]  # Default to excluding label 0\n",
    "        self.labels_to_exclude = labels_to_exclude\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Convert predictions to class labels\n",
    "        y_pred = tf.math.argmax(y_pred, axis=-1)\n",
    "\n",
    "        # Flatten the tensors\n",
    "        y_true = tf.reshape(y_true, [-1])\n",
    "        y_pred = tf.reshape(y_pred, [-1])\n",
    "\n",
    "        # Apply mask to exclude specified labels  ->IMPORTANT FOR HOMEWORK\n",
    "        for label in self.labels_to_exclude:\n",
    "            mask = tf.not_equal(y_true, label)\n",
    "            y_true = tf.boolean_mask(y_true, mask)\n",
    "            y_pred = tf.boolean_mask(y_pred, mask)\n",
    "\n",
    "        # Update the state\n",
    "        return super().update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "# Visualization callback\n",
    "class VizCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, X_val, y_val,  frequency=5):\n",
    "        super().__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.num_classes = 5\n",
    "        self.frequency = frequency\n",
    "        self.print= False\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % self.frequency == 0:  # Visualize only every \"frequency\" epochs\n",
    "            if self.print:\n",
    "                print(\"X_val shape:\", self.X_val.shape)\n",
    "                print(\"y_val shape:\", self.y_val.shape)\n",
    "\n",
    "            image = self.X_val\n",
    "            label = self.y_val\n",
    "            if self.print:\n",
    "                print(\"Images shape:\", image.shape)\n",
    "                print(\"Labels shape:\", label.shape)\n",
    "            \n",
    "            image = tf.expand_dims(image, 0)\n",
    "            pred = self.model.predict(image, verbose=0) #300x64x128x5 [0,1]\n",
    "            y_pred = tf.math.argmax(pred, axis=-1) #300x64x128 [0,4]\n",
    "            y_pred = y_pred.numpy() \n",
    "\n",
    "            if self.print:\n",
    "                print(\"pred shape:\", pred.shape)\n",
    "                print(\"y_pred shape:\", y_pred.shape)\n",
    "\n",
    "\n",
    "            \n",
    "            # Create colormap\n",
    "            colormap = create_segmentation_colormap(self.num_classes)\n",
    "\n",
    "            plt.figure(figsize=(16, 4))\n",
    "\n",
    "            # Input image\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(image[0])\n",
    "            plt.title(\"Input Image\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            # Ground truth\n",
    "            plt.subplot(1, 3, 2)\n",
    "            colored_label = apply_colormap(label, colormap)\n",
    "            plt.imshow(colored_label)\n",
    "            plt.title(\"Ground Truth Mask\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            # Prediction\n",
    "            plt.subplot(1, 3, 3)\n",
    "            colored_pred = apply_colormap(y_pred[0], colormap)\n",
    "            plt.imshow(colored_pred)\n",
    "            plt.title(\"Predicted Mask\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "# Compile the model\n",
    "print(\"Compiling model...\")\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.AdamW(LEARNING_RATE),\n",
    "    metrics=[\"accuracy\", MeanIntersectionOverUnion(num_classes=num_classes, labels_to_exclude=[0])]\n",
    ") #accuracy is pixelwise, not very relevant but still useful for some small objects such as cars. the second custom measure is much better\n",
    "print(\"Model compiled!\")\n",
    "# Setup callbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    patience=PATIENCE,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "viz_callback = VizCallback(tf.convert_to_tensor(X_val[0]), tf.convert_to_tensor(y_val[0]),5)\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[early_stopping, viz_callback],\n",
    "    verbose=1\n",
    ").history\n",
    "\n",
    "# Calculate and print the final validation accuracy\n",
    "final_val_meanIoU = round(max(history['val_mean_iou'])* 100, 2)\n",
    "print(f'Final validation Mean Intersection Over Union: {final_val_meanIoU}%')\n",
    "\n",
    "# Save the trained model to a file with the accuracy included in the filename\n",
    "model_filename = 'UNet_'+str(final_val_meanIoU)+'.keras'\n",
    "model.save(model_filename)\n",
    "\n",
    "# Delete the model to free up resources\n",
    "del model\n",
    "# Plot and display training and validation loss\n",
    "plt.figure(figsize=(18, 3))\n",
    "plt.plot(history['loss'], label='Training', alpha=0.8, color='#ff7f0e', linewidth=2)\n",
    "plt.plot(history['val_loss'], label='Validation', alpha=0.9, color='#5a9aa5', linewidth=2)\n",
    "plt.title('Cross Entropy')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Plot and display training and validation accuracy\n",
    "plt.figure(figsize=(18, 3))\n",
    "plt.plot(history['accuracy'], label='Training', alpha=0.8, color='#ff7f0e', linewidth=2)\n",
    "plt.plot(history['val_accuracy'], label='Validation', alpha=0.9, color='#5a9aa5', linewidth=2)\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Plot and display training and validation mean IoU\n",
    "plt.figure(figsize=(18, 3))\n",
    "plt.plot(history['mean_iou'], label='Training', alpha=0.8, color='#ff7f0e', linewidth=2)\n",
    "plt.plot(history['val_mean_iou'], label='Validation', alpha=0.9, color='#5a9aa5', linewidth=2)\n",
    "plt.title('Mean Intersection over Union')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
